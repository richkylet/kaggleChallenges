{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime data\n",
    "\n",
    "Download data here https://www.kaggle.com/c/sf-crime/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial preview of data:\n",
    "We are only going to work with the train data for right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category  DayOfWeek PdDistrict           X  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS  Wednesday   NORTHERN -122.425892   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES  Wednesday   NORTHERN -122.425892   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES  Wednesday   NORTHERN -122.424363   \n",
       "3  2015-05-13 23:30:00   LARCENY/THEFT  Wednesday   NORTHERN -122.426995   \n",
       "4  2015-05-13 23:30:00   LARCENY/THEFT  Wednesday       PARK -122.438738   \n",
       "\n",
       "           Y  \n",
       "0  37.774599  \n",
       "1  37.774599  \n",
       "2  37.800414  \n",
       "3  37.800873  \n",
       "4  37.771541  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_df = pd.read_csv(\"/Users/KRich/GitHub/data/SF crime/train.csv\")\n",
    "# remove address, resolution and description\n",
    "crime_df = crime_df.drop(['Address','Resolution','Descript'],axis=1)\n",
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 6 columns):\n",
      "Dates         878049 non-null object\n",
      "Category      878049 non-null object\n",
      "DayOfWeek     878049 non-null object\n",
      "PdDistrict    878049 non-null object\n",
      "X             878049 non-null float64\n",
      "Y             878049 non-null float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 40.2+ MB\n"
     ]
    }
   ],
   "source": [
    "crime_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest score:0.857532113109\n",
      "Logistic regression score:0.228404174597\n"
     ]
    }
   ],
   "source": [
    "def data_load():\n",
    "    # IMPORT DATA --------------------------\n",
    "    crime_df = pd.read_csv(\"/Users/KRich/GitHub/data/SF crime/train.csv\")\n",
    "    # drop address, Resolution, and Descript (not useful for prediction)\n",
    "    crime_df = crime_df.drop(['Address','Resolution','Descript'],axis=1)\n",
    "    return crime_df\n",
    "def data_split(crime_df):\n",
    "    # SPLIT DATA:---------------------------\n",
    "    # train data:\n",
    "    Xtrain = crime_df.sample(frac=0.8, random_state=1)\n",
    "    YTrain = Xtrain[\"Category\"]    \n",
    "    Xtrain = Xtrain.drop('Category', axis=1)\n",
    "    # test data (anything not in train):\n",
    "    Xtest  = crime_df.loc[~crime_df.index.isin(Xtrain.index)]\n",
    "    Xtest  = Xtest.drop(\"Category\", axis=1)\n",
    "    return Xtrain, YTrain, Xtest\n",
    "#-------------------------------\n",
    "def data_categorize(Xdata):\n",
    "    # create dummy categorical values and drop the former var:\n",
    "    X = Xdata\n",
    "    # date/time categorical features\n",
    "    hours  = pd.get_dummies(X.Dates.map(lambda x: pd.to_datetime(x).hour), prefix=\"hour\")\n",
    "    months = pd.get_dummies(X.Dates.map(lambda x: pd.to_datetime(x).month), prefix=\"month\")\n",
    "    years  = pd.get_dummies(X.Dates.map(lambda x: pd.to_datetime(x).year), prefix=\"year\")\n",
    "    # district categorical features\n",
    "    district = pd.get_dummies(X[\"PdDistrict\"])\n",
    "    X = X.drop(\"PdDistrict\", axis=1)\n",
    "    # day of the week categorical features\n",
    "    day_of_week = pd.get_dummies(X[\"DayOfWeek\"])\n",
    "    X = X.drop(\"DayOfWeek\", axis=1)\n",
    "    # string together \n",
    "    X = pd.concat([X, hours, months, years, district, day_of_week], axis=1)\n",
    "    # drop the year of 2015 (see: _Viz_SanFranCrime; 2015 not complete)\n",
    "    X = X.drop('year_2015' , axis=1)#[X.year_2015 != '2015']\n",
    "    X = X.drop(\"Dates\", axis=1)\n",
    "    return X\n",
    "#-------------------------------\n",
    "def rand_forest(Xtrain, Ytrain, Xtest):  \n",
    "    # model\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    # fit\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    # predict\n",
    "    predictions = clf.predict(Xtest)\n",
    "    #score\n",
    "    rf_score = clf.score(Xtrain, Ytrain)\n",
    "    print('Random forest score:' + str(rf_score))\n",
    "    # predict\n",
    "    y_test = pd.DataFrame(clf.predict_proba(Xtest), index=Xtest.index, columns=clf.classes_)\n",
    "    return rf_score\n",
    "#-------------------------------\n",
    "def log_regress(Xtrain, Ytrain, Xtest):\n",
    "    # model\n",
    "    LogRegModel = LogisticRegression()\n",
    "    # fit\n",
    "    LogRegModel.fit(Xtrain, Ytrain)\n",
    "    # predict\n",
    "    predictions = LogRegModel.predict(Xtest)\n",
    "    # score\n",
    "    log_score = LogRegModel.score(Xtrain, Ytrain)\n",
    "    print('Logistic regression score:' + str(log_score))\n",
    "#-------------------------------\n",
    "def main():\n",
    "    # load data\n",
    "    df = data_load()\n",
    "    # split data train/test\n",
    "    Xtrain, Ytrain, Xtest = data_split(df)\n",
    "    # process vars\n",
    "    Xtrain = data_categorize(Xtrain)\n",
    "    Xtest  = data_categorize(Xtest)\n",
    "    # random forests, predict and score\n",
    "    rand_forest(Xtrain, Ytrain, Xtest)\n",
    "    # logistic regression\n",
    "    log_regress(Xtrain, Ytrain, Xtest)\n",
    "#-------------------------------\n",
    "              \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
